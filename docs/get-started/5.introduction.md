---
id: 'introduction'  
title: 'Introduction'  
sidebar_position: 5
---  

# What is Apache StreamParkâ„¢?
ğŸš€ **A magical framework that makes stream processing simpler!**

> In the realm of real-time processing, Apache Sparkâ„¢ and Apache FlinkÂ® represent significant advancements, especially Flink, which is widely considered the next-generation big data stream processing engine. Through our experience with Apache FlinkÂ® and Apache Sparkâ„¢, we discovered many parts of the programming model, startup configurations, and operation management that could be abstracted and shared. We solidified some of these excellent experiences and combined them with industry best practices. After relentless effort, we created: **`Apache StreamParkâ„¢`**.

![screenshot](/home/screenshot.png)

**`Apache StreamParkâ„¢` is an all-in-one stream processing platform**. It standardizes project configurations, encourages functional programming, defines the best programming practices, and provides a series of out-of-the-box connectors. It standardizes the entire process from configuration, development, testing, deployment, monitoring, to operation and maintenance. It offers both Scala and Java interfaces and provides a one-stop platform for stream processing job development and management, supporting the full lifecycle from development to deployment. Using Apache StreamParkâ„¢ to develop stream processing jobs can significantly reduce the learning curve and development threshold, allowing developers to focus on core business logic.

## Core Features

<h6> ğŸ‰ Application Development Scaffold</h6>

**Apache StreamParkâ„¢** provides an easy-to-use development framework that enables developers to efficiently build stream processing applications. It <u>**supports multiple versions**</u> of Apache FlinkÂ® and Apache Sparkâ„¢, lowering the learning cost and development threshold, and allowing developers to focus on core business logic.

![mutiple_version](/doc/image/quick-start/mutiple_version.png)

<h6> ğŸ‰ Out-of-the-box Connectors</h6>

**Apache StreamParkâ„¢** offers a series of <u>**out-of-the-box**</u> connectors that simplify integration with various data sources and destinations. These connectors make data acquisition and processing more efficient, supporting various data scenarios.

![connectors](/doc/image/quick-start/connectors.png)

<h6> ğŸ‰ One-stop Stream Processing Operations Platform</h6>

As an all-in-one stream processing operations platform, **Apache StreamParkâ„¢** <u>**integrates development, debugging, deployment, and operational management functions**</u>. It provides a low-code platform via `streampark-console`, making it easier for users to manage Flink tasks and simplifying operations such as project compilation, publishing, and parameter configuration.

![cicd](/doc/image/quick-start/cicd.png)

<h6> ğŸ‰ Supports Various Scenarios</h6>

**Apache StreamParkâ„¢** supports a variety of application scenarios, including Catalog, OLAP, and Streaming Warehouse. This enables users to flexibly apply Apache StreamParkâ„¢ to meet the needs of real-time data analysis and processing.

<h6> ğŸ‰ ...</h6>

## Architecture Design
ğŸ³â€ğŸŒˆ The core of **Apache StreamParkâ„¢** consists of `StreamPark Core` and `StreamPark Console`:

![StreamPark Archite](/doc/image_en/streampark_archite.png)

### StreamPark Core

**StreamPark Core** is positioned as a development framework focused on coding. It standardizes configuration files and adopts a "convention over configuration" approach to development. It provides a development environment's `RuntimeContext` and a series of out-of-the-box connectors, extending methods related to `DataStream`. It integrates `DataStream` and Flink SQL API, simplifying operations, focusing on business logic, and improving development efficiency and experience.

### StreamPark Console

**StreamPark Console** is a platform that integrates real-time data processing with low-code development. It efficiently manages Flink tasks and integrates functions like project compilation, publishing, parameter configuration, startup, savepoints, flame graphs, Flink SQL, and monitoring. It greatly simplifies the daily operation and maintenance of Flink tasks, incorporating many best practices. The platform enables projects, which were previously only accessible to large companies, to be available to everyone. Its goal is to create a real-time data warehouse and a unified big data solution for both stream and batch processing. The platform uses the following technologies (but not limited to):

- Â· [Apache Flink](http://flink.apache.org)
- Â· [Apache Spark](http://spark.apache.org)
- Â· [Apache YARN](http://hadoop.apache.org)
- Â· [Spring Boot](https://spring.io/projects/spring-boot/)
- Â· [Mybatis](http://www.mybatis.org)
- Â· [Mybatis-Plus](http://mp.baomidou.com)
- Â· [Vue](https://cn.vuejs.org/)
- Â· [VuePress](https://vuepress.vuejs.org/)
- Â· [Ant Design of Vue](https://antdv.com/)
- Â· [ANTD PRO VUE](https://pro.antdv)
- Â· [xterm.js](https://xtermjs.org/)
- Â· [Monaco Editor](https://microsoft.github.io/monaco-editor/)
- Â· ...

Special thanks to these and many other excellent open-source projects, with the utmost respect!

---

Feel free to use this directly! Let me know if you'd like to tweak anything further.